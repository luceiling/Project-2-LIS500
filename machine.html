<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="keywords" content="intersectionality, implicit bias test, bias, implicit association test, equity">
        <meta name="author" content="HTML: Larkspur Domka; CSS: Lucy Mackintosh">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>LIS 500 Project 2 Resources</title>
        <link rel="stylesheet" href="stylepage.css">
    </head>
    <body>
        
        <!-- Top navigation bar -->
        <div class="topnav">
            <form action="index.html">
                <button type="submit" class="btn">Home</button>
            </form>
            <form action="about.html">
              <button type="submit" class="btn">About Us</button>
            </form>
            <form action="resources.html">
             <button type="submit" class="btn">Resources</button>
            </form>
            <form action="hero.html">
             <button type="submit" class="btn">Tech Heroes</button>
            </form>
            <form action="machine.html">
            <button type="submit" class="btn">Machine Learning</button>
            </form>
        </div>
        
        <!--about the model-->
        
        <h1 class="home">Project Purpose</h1>
        <h2 class="sectionTitle">What we did</h2>
        <h3>Step 1: Planning</h3>
        <p class="reflectBody">
            We had multiple Zoom meetings to plan out the process and ideas we had. We started ambitious, thinking we could do focus on training a machine to learn biomes or seasons, but we decided that, with how broad that category could be and how diverse each area shows its seasons, it may be too difficult to do. We also wanted to use mostly our own images in the model. Lark had some photos of Minnesota wilderness, but we would be a bit beholden to the region and seasons he had photographed. <br><br>
            But through this line of thinking, because of Lark's art, we decided that it would be interesting to explore whether AI would be able to tell the difference between art and human. We extended this a bit to "not real human" and "real human" to be a little more objective in our model. 
        </p>
        <h3>Step 2: Compiling Images</h3>
        <h4>Lark:</h4>
        <p class="reflectBody">
            With my BA in studio art, I have a moderately sized portfolio of work to pull images from. One of the visual art styles I specialized in for my degree was hyperrealism/magical realism--I took real objects and figures and added surreal or fantastical elements/qualities to them.<br><br>
            After reading Boulamwini's book, it had me thinking about a machine's capability to detect the presence of real humans. I wondered if it would be able to differentiate between non-photographic art objects depicting humans/human anatomy and images that might contain similar patterns of hue/saturation/value mapping vs images that contain real humans, including images of real humans that had been edited and stylized with touch-ups and color adjustments.<br><br>
            A  note on what I mean when I say "hue/saturation/value mapping" for those not as versed in color theory: every color, both in real life and virtual, has, at minimum, three core properties which are used to describe how it is generally perceived by the human eye. The three qualities are hue (red, yellow, green, and blue are hues), saturation (how intense or "pure" a color is vs. how close it is to white/gray/black), and value (how light or dark a color is).  You may have heard of or seen "HSV", which is an abbreviation for hue/saturation/value, and is a color model used in graphic design.  In order for computers to display different colors, there are a few code systems in existence that essentially calculate or designate the HSV of every pixel displayed on the monitor. Similar to how HTML is a language for web page structure, there are also computing "languages" of colors (hexadecimal, RGB, CMYK, etc.).  All the pixels of an image taken together create a map of color codes--I would hypothesize that teachable machines use some of this color information when learning from image data. Therein, a realistic human figure drawing could have similar shapes/patterns of color value data as a photo of a human, even if the drawing is in grayscale.  So if the algorithm is leaning on a specific color property more than others for determining whether an image contains a real human or not, that could impact its output confidence.<br><br>
            I chose images of figure drawings I did, and one hyperrealistic digital painting I made of a friend; only the figure is painted in that image, the background is the original photo.  I also added various more "professional" photos I took of landscapes and people, including photos of myself.  Some of these photos have minor touch-ups, HSV adjustments done in editing, or are close-ups on particular human anatomy (hands, fingers, mouths, etc.).  My hope was that the algorithm would be able to then pick up on whether real/photographed human anatomy was present in any part of any given image.<br><br>
            Some shortcomings of the dataset were that I haven't done enough photoshoots of people to have a diverse portfolio of human/figure-based photography.  I had photographed myself, a couple of former housemates, and someone else I went to undergrad with, all of whom are white or otherwise lighter-skinned.  Lucy added some stock photos of other humans for greater diversity.  In searching through my files, I also realized I have lost some of the higher quality images I had of my non-photographic artwork, and a number of my art pieces were damaged in a flood a few years back so trying to photograph them now unfortunately wouldn't have done much good.
        </p>
        <h3>Step 3: Training the Model and Programming the Model</h3>
        <h3>Training the Model</h3>
        <p class="reflectBody">
            We used <a href="https://teachablemachine.withgoogle.com/" target="_blank">Google's teachable machine</a> to analyze our images and create a model we could use to finally create <a href="https://teachablemachine.withgoogle.com/models/Q0Tl7D-bs/" target="_blank">our basic model</a>. The image selection process is discussed above.</p>
        <h3>Programming the Model</h3>
        <p class="reflectBody">We debated making the program specifically only use live image input, and created the program for that, but decided that it did not work for what we wanted. The main issue with the video feed was that, probably because of our lower sample base, there was too much variation of results even when there was little movement on camera.<br><br>The three of us agreed that we liked the image uploader on the basic Google model better for our preferences, so Lucy <a href="https://editor.p5js.org/luceiling/sketches/72J3BSUOr" target="_blank"> redid the code on p5js.org</a> to make uploading images an option. Thankfully, there are a ton of resources available to make this process a little easier, and Lucy was able to find a guide that walked through this process. While some issues still exist, like the dimensions of the images stretching, making some of them look a little weird and maybe impacting the results of the model (e.g., some of the images we used in the model only show up with 0.99 confidence), this still ended up working really well and having a more consistent confidence rating over the video feed version. See the video below to see how it works, or try it out yourself!
        </p>
        <h2 class="sectionTitle">Results</h2>
            <div style="text-align: center;">
                <form action="indexml.html" target="_blank>">
                    <button type="submit" class="btn" id="iat-btn">Try Out Our Machine Learning Model</button>
                </form>
            </div>
        <center>
            <video width="640" height="480" style="text-align: center" controls>
                <source src="LIS%20500%20Machine%20Learning%20Showcase%20-%20Made%20with%20Clipchamp.mp4" type="video/mp4">
                Your browser does not support the video tag
            </video>
        </center>
        <h2 class="sectionTitle">Reflection</h2>
        <p class="reflectBody">
            Working on this project gave us a much greater understanding of Buolamwini’s book. Particularly, we gained more perspective on the complications with training an AI, how bias can negatively impact the results, and the issues of collecting a large dataset. The first aspect of Buolamwini’s book that came up while we worked was the question of consent. Buolamwini states, “Was the data obtained with consent? What were the working conditions and compensation for the workers who processed the data?” (Buolamwini 68). This was one of our chief concerns when we started the project. Where would we obtain our images? How would we ensure we obtained the images legally? We did not want to illegally obtain images, stealing images that the artists worked hard on. There was no chance of the artists getting compensation from our usage. We almost immediately decided to use our own images to avoid this issue, but this is not a viable solution when thousands or even millions of images are needed. 
            <br><br>
            Staying on the topic of consent, it played a major role in how we chose our topic. Lucy almost immediately inquired about the scope of the data because where to get the images was a major concern. We did not want to collect images without the consent of the people who took them/were featured in them. Buolamwini reflected on this struggle, saying, “Nevertheless, lawful use did not overcome the basic fact that I would be using images of people’s faces without their consent to do this research, unless I could somehow obtain the consent of the 1,270 individuals who would be included in the dataset” (113). While we settled on using our own images, what would we have done if we needed a bigger dataset? If we needed hundreds or thousands of images, we would have had to use images without consent, which felt wrong. Buolamwini’s (113) concerns were shot down, which is surprising. Our project has way less real-world implications than Buolamwini’s and we still considered this to be a major concern. 
            <br><br>
            Another concern that came up as we worked was the AI’s ability to recognize us as human. The AI failed to consistently recognize us as human, which can be incredibly concerning in a real-world context. Buolamwini (71) expresses two concerns with AI facial recognition; she discusses difficulty she had with joining a dating app because it used AI that did not recognize her face, and she talks about someone who was incarcerated based on a false facial recognition match. While we will not be using our AI in these kinds of real-world situations, these examples show the issue that our AI’s inability to recognize some faces as human can cause. Based on Buolamwini’s findings, we cannot use our AI in the real world. With our limited dataset, it can cause issues ranging from being unable to use certain apps to false arrests. What if something similar to our AI was used for a captcha? How many people would not be able to use the Internet adequately? 
            <br><br>
            This quote from Buolamwini (94) reflects why our results may not be perfect and why our dataset is limited, “This is not always the case, particularly when the experts do not reflect the rest of society.” We did not go into this project with any malice, but we have a limited dataset, based on the people, drawings, and environments we have access to. We do not represent society as a whole, so our dataset also does not represent society as a whole. The big difference between us and Buolamwini’s example is what we have access to. We used our own images, while the experts have access to millions of images. They should have access to a diverse range of data, but they do not include it when training AI models. Buolamwini also mentions that the government dataset had a slight majority of light-skinned males, with less than five percent of the dataset being dark-skinned females (94). This has been a concern during our project. We do not have a diverse set of humans for the AI to learn from. The AI is generally very accurate, but it would certainly be more accurate if we had a more diverse set of data. 
            <br><br>
            When Buolamwini (107-108) was working on classification, she struggled with the bias that comes with naming the different classifications, finally settling on something more objective. She settled on the specific color of people’s skin, rather than race or ethnicity because it is “more specific and objective” (Buolamwini 108). This resonated with us as we decided how to do our own classifications. We settled on the classifications of real human vs. not real human because it is objective. Our project does not have as many complications as Buolamwini’s in this regard, but remaining objective with our classifications was still something we took away from her work. 
            <br><br>
            Buolamwini finishes off her novel with a poem titled “Still Uncompleted,” which resonates with what we learned. The people training AI, like we did during this project, need to view humanity as more than data. So many things need to be considered when working with AI. We considered so many issues while working on this project, and I doubt we would have made these considerations without reading Buolamwini’s book. Consent is certainly a tricky aspect of AI, but it needs to be at least considered. Most people would not be happy with their face being used to train AI, so it is concerning that their likeness can be used without consent. It is also concerning that people’s labor is being used to train AI without their work being compensated. There are concerns of our AI not being perfect, but we understand why it has some issues. Our dataset was limited, which is an issue Buolamwini repeatedly drove home. We spent a lot of time thinking about how to classify our data, settling on something objective like Buolamwini chose to. So many of Buolamwini’s concerns about AI resonated deeply with us as we worked on this project, and we hope that more experts make these considerations as they work with AI, because lack of these considerations can have massive consequences. 
</p>
    </body>
</html>
        
